// Chargement des d√©pendances
require("dotenv").config(); // Charge les variables d'environnement
const express = require("express");
const bodyParser = require("body-parser");
const { Configuration, OpenAIApi } = require("openai");
const cors = require("cors");

const app = express();
const port = 3000;

// Configuration de l'API OpenAI
const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);

// Middleware
app.use(cors());
app.use(bodyParser.json());

// Stocke les sessions utilisateur
const sessions = {};

// Route GET pour la racine "/"
app.get("/", (req, res) => {
  res.send("Le serveur est op√©rationnel ! üåü");
});

// Endpoint principal
app.post("/api/chat", async (req, res) => {
  const userId = req.body.userId || "default"; // Identifie l'utilisateur
  if (!sessions[userId]) {
    sessions[userId] = { context: {}, waitingForAnswer: null, lastUserMessage: null }; // Initialise une nouvelle session
  }

  const session = sessions[userId];
  const userMessage = req.body.message;
  const conversation = req.body.conversation || []; // Conserve la conversation pour un contexte complet

  if (!session.lastUserMessage) {
    session.lastUserMessage = userMessage; // Stocke le message initial de l'utilisateur
  }

  // Analyse dynamique pour d√©tecter les informations manquantes
  const dynamicQuestions = [
    { key: "age", question: "Quel √¢ge a votre enfant ?" },
    { key: "gender", question: "Votre enfant est-il une fille ou un gar√ßon ?" },
    { key: "sibling_position", question: "Quelle est sa place dans la fratrie ? (a√Æn√©, cadet, benjamin)" },
    { key: "single_parent", question: "Vivez-vous dans une famille monoparentale ?" },
  ];

  if (session.waitingForAnswer) {
    // Si une r√©ponse est attendue, l'ajouter au contexte
    session.context[session.waitingForAnswer] = userMessage;
    session.waitingForAnswer = null; // R√©initialise l'attente

    if (session.context.pendingReply) {
      // Envoie la suite de la r√©ponse s'il y en a une
      const nextPart = session.context.pendingReply;
      session.context.pendingReply = null;
      return res.json({ reply: nextPart });
    }

    // Si une r√©ponse est en attente, poser une nouvelle question ou continuer la r√©ponse
    const missingInfo = dynamicQuestions.find((q) => !session.context[q.key]);
    if (missingInfo) {
      session.waitingForAnswer = missingInfo.key;
      return res.json({ reply: missingInfo.question });
    }

    return res.json({ reply: "Merci pour ces pr√©cisions ! Que puis-je faire pour vous maintenant ?" });
  }

  // V√©rifie si des informations sont n√©cessaires
  const missingInfo = dynamicQuestions.find((q) => !session.context[q.key]);

  if (missingInfo) {
    session.waitingForAnswer = missingInfo.key;
    return res.json({ reply: missingInfo.question });
  }

  // Pr√©paration du message complet avec le contexte
  const messages = [
    {
      role: "system",
      content: `
      Tu es NORR, un assistant parental chaleureux et compatissant, inspir√© par l'approche de Lulumineuse. 
      Ton r√¥le est d'accompagner les parents avec bienveillance et de les aider √† int√©grer la spiritualit√© 
      dans leur quotidien familial. Sois clair, direct, engageant et propose des solutions pratiques tout 
      en inspirant confiance et s√©r√©nit√©.

      Voici les informations utilisateur disponibles :
      - √Çge : ${session.context.age || "non sp√©cifi√©"}
      - Sexe : ${session.context.gender || "non sp√©cifi√©"}
      - Place dans la fratrie : ${session.context.sibling_position || "non sp√©cifi√©"}
      - Famille monoparentale : ${session.context.single_parent || "non sp√©cifi√©"}

      Souviens-toi, tu es l√† pour soutenir, rassurer et guider les parents avec respect et empathie.
      `,
    },
    { role: "user", content: session.lastUserMessage }, // Reprend la question originale de l'utilisateur
    ...conversation, // Int√®gre la conversation compl√®te re√ßue
  ];

  try {
    const completion = await openai.createChatCompletion({
      model: "gpt-4-turbo",
      messages: messages,
    });

    const fullReply = completion.data.choices[0].message.content;

    // Diviser la r√©ponse si elle est longue
    const maxLength = 300; // Limite de caract√®res par r√©ponse
    if (fullReply.length > maxLength) {
      const firstPart = fullReply.slice(0, maxLength);
      const secondPart = fullReply.slice(maxLength);

      session.context.pendingReply = secondPart; // Stocke la partie restante

      return res.json({
        reply: `${firstPart}\n\nSouhaitez-vous plus de d√©tails ? R√©pondez par "oui" pour continuer.`,
      });
    }

    return res.json({ reply: fullReply });
  } catch (error) {
    console.error("Erreur OpenAI :", error);
    return res.status(500).json({ error: "Erreur lors de la g√©n√©ration de la r√©ponse." });
  }
});

// D√©marrage du serveur
app.listen(port, () => {
  console.log(`Serveur en cours d'ex√©cution sur http://localhost:${port}`);
});



