const express = require("express");
const app = express();
const PORT = process.env.PORT || 3000;
const fetch = require("node-fetch");
require("dotenv").config();
const cors = require("cors");

// Configuration CORS
app.use(
  cors({
    origin: "*", // Remplace par ton domaine Shopify en production
    methods: ["GET", "POST"],
    allowedHeaders: ["Content-Type", "Authorization"],
  })
);

app.use(express.json());

let conversation = []; // Unique conversation pour tous les utilisateurs

app.get("/", (req, res) => {
  res.send("Bienvenue sur l'API ChatGPT !");
});

app.post("/api/chatgpt", async (req, res) => {
  const { message } = req.body;

  console.log("Message re√ßu du frontend :", message);

  if (!message) {
    res.status(400).json({ error: "Le champ 'message' est requis." });
    return;
  }

  // Ajout du message de l'utilisateur √† la conversation
  conversation.push({ role: "user", content: message });

  // Limitation du contexte conversationnel (garde uniquement les 20 derniers messages)
  if (conversation.length > 20) {
    conversation.shift(); // Supprime les messages les plus anciens
  }

  console.log("Messages envoy√©s √† OpenAI :", [
    { 
      role: "system", 
      content: "Tu es un assistant parental bienveillant et utile. Accueille les utilisateurs avec ce message : 'Bonjour √† vous‚ÄØ! √ätre parent est une aventure unique, et je suis l√† pour vous √©pauler. Vous pourrez m‚Äôappeler NORR üòâ. Pour des conseils personnalis√©s, n‚Äôh√©sitez pas √† inclure dans votre question des informations comme l'√¢ge, le sexe, et la place de votre enfant dans la fratrie. Je suis l√† pour vous accompagner‚ÄØ!'. Si une question manque de pr√©cisions importantes, demande les informations n√©cessaires avant de r√©pondre, mais uniquement si elles sont pertinentes. Tes r√©ponses doivent √™tre courtes et claires. Si tu penses que ta r√©ponse sera coup√©e, termine par 'Souhaitez-vous que je continue‚ÄØ?'."
    },
    ...conversation,
  ]);

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4-turbo",
        messages: [
          { 
            role: "system", 
            content: "Tu es un assistant parental bienveillant et utile. Accueille les utilisateurs avec ce message : 'Bonjour √† vous‚ÄØ! √ätre parent est une aventure unique, et je suis l√† pour vous √©pauler. Vous pourrez m‚Äôappeler NORR üòâ. Pour des conseils personnalis√©s, n‚Äôh√©sitez pas √† inclure dans votre question des informations comme l'√¢ge, le sexe, et la place de votre enfant dans la fratrie. Je suis l√† pour vous accompagner‚ÄØ!'. Si une question manque de pr√©cisions importantes, demande les informations n√©cessaires avant de r√©pondre, mais uniquement si elles sont pertinentes. Tes r√©ponses doivent √™tre courtes et claires. Si tu penses que ta r√©ponse sera coup√©e, termine par 'Souhaitez-vous que je continue‚ÄØ?'."
          },
          ...conversation,
        ],
        max_tokens: 350, // Limite l√©g√®rement augment√©e
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("Erreur avec OpenAI :", errorText);
      res.status(500).json({ error: "Erreur avec OpenAI." });
      return;
    }

    const data = await response.json();

    console.log("R√©ponse re√ßue d'OpenAI :", data);

    const aiMessage = data.choices[0].message;

    // V√©rifie si la r√©ponse est coup√©e
    const isCutOff = data.choices[0].finish_reason === "length";

    if (isCutOff) {
      console.log("La r√©ponse a √©t√© coup√©e par la limite de tokens.");
      aiMessage.content += "\n\nSouhaitez-vous un autre conseil ou des d√©tails suppl√©mentaires ?";
    }

    console.log("R√©ponse envoy√©e au frontend :", aiMessage.content);

    // Ajout de la r√©ponse de l'IA √† la conversation
    conversation.push(aiMessage);

    // Envoie la r√©ponse au frontend
    res.json({ content: aiMessage.content });
  } catch (error) {
    console.error("Erreur interne :", error.message);
    res.status(500).json({ error: "Erreur interne du serveur." });
  }
});

app.listen(PORT, () =>
  console.log(`Serveur en cours d'ex√©cution sur http://localhost:${PORT}`)
);










