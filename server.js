// Chargement des dÃ©pendances
require("dotenv").config();
const express = require("express");
const bodyParser = require("body-parser");
const { Configuration, OpenAIApi } = require("openai");
const cors = require("cors");

const app = express();
const port = 3000;

// Configuration de l'API OpenAI
const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);

// Middleware
app.use(cors());
app.use(bodyParser.json());

// Route GET pour vÃ©rifier que le serveur fonctionne
app.get("/", (req, res) => {
  res.send("ğŸš€ Serveur NORR opÃ©rationnel !");
});

// Endpoint principal pour le chatbot
app.post("/api/chat", async (req, res) => {
  console.log("ğŸ“¥ RequÃªte reÃ§ue sur /api/chat :", req.body);

  if (!req.body.conversation || !Array.isArray(req.body.conversation)) {
    return res.status(400).json({ error: "â›” Le champ 'conversation' est requis et doit Ãªtre un tableau." });
  }

  // VÃ©rifier si la question concerne un enfant et si l'Ã¢ge est manquant
  const userMessage = req.body.conversation[req.body.conversation.length - 1].content.toLowerCase();
  const ageMentionnÃ© = /\b(\d+)\s?(an|ans)\b/.test(userMessage);

  if (userMessage.includes("mon enfant") || userMessage.includes("ma fille") || userMessage.includes("mon fils")) {
    if (!ageMentionnÃ©) {
      return res.json({ reply: "Quel est l'Ã¢ge de votre enfant pour que je puisse rÃ©pondre plus prÃ©cisÃ©ment ?" });
    }
  }

  try {
    const messages = [
  {
    role: "system",
    content: `
      Tu es NORR, un assistant parental chaleureux et compatissant.
      Tu es lÃ  pour aider les parents Ã  naviguer dans leurs dÃ©fis quotidiens avec bienveillance et clartÃ©.
      Tu t'appuies sur les travaux d'Isabelle Filiozat, Emmanuelle Piquet et Lulumineuse pour enrichir tes conseils avec des perspectives psychologiques et spirituelles.

      ğŸ¯ **Objectifs de ton discours :**
      - Reste **naturel et humain**, Ã©vite un ton trop acadÃ©mique ou mÃ©canique.
      - **Engage-toi Ã©motionnellement** : montre de l'empathie et fais sentir Ã  l'utilisateur qu'il est compris.
      - **Utilise un langage fluide et accessible** : Ã©vite les longues explications trop didactiques.
      - **Pose des questions pour inviter l'utilisateur Ã  interagir** plutÃ´t que de donner une rÃ©ponse complÃ¨te dâ€™un coup.
      
      **Exemples de tournures naturelles** :
      - "Ah, c'est une situation dÃ©licate ! Je comprends que Ã§a puisse Ãªtre frustrant..."
      - "Je vois, et vous avez dÃ©jÃ  essayÃ© quelque chose pour gÃ©rer Ã§a ?"
      - "Un truc qui marche souvent, câ€™est..."
      - "Vous aimeriez explorer cette piste ensemble ?"

      âœ… **RÃ¨gles supplÃ©mentaires :**
      - Si la rÃ©ponse risque d'Ãªtre longue, demande avant : "Souhaitez-vous que je dÃ©veloppe cette idÃ©e ?"
      - Si l'utilisateur donne un Ã¢ge approximatif (ex: "vers 5 ans"), demande un Ã¢ge prÃ©cis.
    `,
  },
  ...req.body.conversation, 
];


    const completion = await openai.createChatCompletion({
      model: "gpt-4-turbo",
      messages: messages,
      max_tokens: 300,  // âš¡ Limite la rÃ©ponse pour accÃ©lÃ©rer le temps de rÃ©ponse
    });

    let fullReply = completion.data.choices[0].message.content;

    // âœ… Anticiper la coupure en ajoutant une question avant d'atteindre 300 tokens
    if (fullReply.length >= 280) {
        fullReply += " [...] Souhaitez-vous que je continue ?";
    }

    console.log("âœ… RÃ©ponse gÃ©nÃ©rÃ©e :", fullReply);

    res.json({ reply: fullReply });
  } catch (error) {
    console.error("âŒ Erreur OpenAI :", error.response ? error.response.data : error.message);
    res.status(500).json({ error: "Erreur serveur lors de la gÃ©nÃ©ration de la rÃ©ponse." });
  }
});

// ğŸš€ DÃ©marrage du serveur
app.listen(port, () => {
  console.log(`ğŸŒ Serveur NORR en cours d'exÃ©cution sur http://localhost:${port}`);
});













