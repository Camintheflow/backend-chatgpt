// Chargement des d√©pendances
require("dotenv").config(); // Charge les variables d'environnement
const express = require("express");
const bodyParser = require("body-parser");
const { Configuration, OpenAIApi } = require("openai");
const cors = require("cors");

const app = express();
const port = 3000;

// Configuration de l'API OpenAI
const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);

// Middleware
app.use(cors());
app.use(bodyParser.json());

// Contexte global pour la session unique
let globalContext = { context: {}, waitingForAnswer: null, lastUserMessage: null };

// Route GET pour v√©rifier que le serveur fonctionne
app.get("/", (req, res) => {
  res.send("Le serveur est op√©rationnel ! üåü");
});

// Endpoint principal
app.post("/api/chat", async (req, res) => {
  const userMessage = req.body.message;
  const conversation = req.body.conversation || []; // Conserve la conversation pour un contexte complet

  if (!globalContext.lastUserMessage && !globalContext.waitingForAnswer) {
    globalContext.lastUserMessage = userMessage; // Stocke le message initial de l'utilisateur
  }

  // Analyse dynamique pour d√©tecter les informations manquantes
  const dynamicQuestions = [
    { key: "age", question: "Quel √¢ge a votre enfant ?" },
    { key: "gender", question: "Votre enfant est-il une fille ou un gar√ßon ?" },
    { key: "sibling_position", question: "Quelle est sa place dans la fratrie ? (a√Æn√©, cadet, benjamin)" },
    { key: "single_parent", question: "Vivez-vous dans une famille monoparentale ?" },
  ];

  if (globalContext.waitingForAnswer) {
    // Si une r√©ponse est attendue, l'ajouter au contexte
    globalContext.context[globalContext.waitingForAnswer] = userMessage;
    globalContext.waitingForAnswer = null; // R√©initialise l'attente

    // V√©rifie s'il reste des informations n√©cessaires
    const nextMissingInfo = dynamicQuestions.find((q) => !globalContext.context[q.key]);
    if (nextMissingInfo) {
      globalContext.waitingForAnswer = nextMissingInfo.key;
      return res.json({ reply: nextMissingInfo.question });
    }

    // Passe au traitement principal si tout est renseign√©
  } else {
    // V√©rifie s'il manque des informations
    const missingInfo = dynamicQuestions.find((q) => !globalContext.context[q.key]);
    if (missingInfo) {
      globalContext.waitingForAnswer = missingInfo.key;
      return res.json({ reply: missingInfo.question });
    }
  }

  // Pr√©paration du message complet avec le contexte
  const messages = [
    {
      role: "system",
      content: `
      Tu es NORR, un assistant parental chaleureux et compatissant, inspir√© par l'approche de Lulumineuse. 
      Ton r√¥le est d'accompagner les parents avec bienveillance et de les aider √† int√©grer la spiritualit√© 
      dans leur quotidien familial. Sois clair, direct, engageant et propose des solutions pratiques tout 
      en inspirant confiance et s√©r√©nit√©.

      Voici les informations utilisateur disponibles :
      - √Çge : ${globalContext.context.age || "non sp√©cifi√©"}
      - Sexe : ${globalContext.context.gender || "non sp√©cifi√©"}
      - Place dans la fratrie : ${globalContext.context.sibling_position || "non sp√©cifi√©"}
      - Famille monoparentale : ${globalContext.context.single_parent || "non sp√©cifi√©"}

      Souviens-toi, tu es l√† pour soutenir, rassurer et guider les parents avec respect et empathie.
      `,
    },
    { role: "user", content: globalContext.lastUserMessage }, // Reprend la question originale de l'utilisateur
    ...conversation, // Int√®gre la conversation compl√®te re√ßue
  ];

  try {
    const completion = await openai.createChatCompletion({
      model: "gpt-4-turbo",
      messages: messages,
    });

    const fullReply = completion.data.choices[0].message.content;

    // Diviser la r√©ponse si elle est longue
    const maxLength = 300; // Limite de caract√®res par r√©ponse
    if (fullReply.length > maxLength) {
      const firstPart = fullReply.slice(0, maxLength);
      const secondPart = fullReply.slice(maxLength);

      globalContext.context.pendingReply = secondPart; // Stocke la partie restante

      return res.json({
        reply: `${firstPart}\n\nSouhaitez-vous plus de d√©tails ? R√©pondez par "oui" pour continuer.`,
      });
    }

    return res.json({ reply: fullReply });
  } catch (error) {
    console.error("Erreur OpenAI :", error);
    return res.status(500).json({ error: "Erreur lors de la g√©n√©ration de la r√©ponse." });
  }
});

// D√©marrage du serveur
app.listen(port, () => {
  console.log(`Serveur en cours d'ex√©cution sur http://localhost:${port}`);
});




